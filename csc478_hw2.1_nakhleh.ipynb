{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### George Nakhleh\n",
    "#### CSC 478: Assignment 2\n",
    "#### Using k-nearest neighbors for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: K-Nearest Neighbor classification on Newsgroups\n",
    "Dataset: [newsgroups.zip](http://facweb.cs.depaul.edu/mobasher/classes/csc478/Data/newsgroups.zip)\n",
    "Dataset description [here](http://qwone.com/~jason/20Newsgroups/)\n",
    "\n",
    "Using a subset of the 20 Newsgroup data set (1000 docs and a vocabulary of terms). Each document belonds to one of two classes: Hockey (label 1) and Microsoft Windows (label 0).  \n",
    "Data has already been split into training and testing sets (80% / 20%), and preprocessed to handle stopwords and perform stemming.  \n",
    "Class labels are provided in separate files. There is a row for each term in the vocabulary and a column for each document, values are raw term frequencies.  \n",
    "For these questions, **scikit-learn won't be used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic EDA\n",
    "Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import packages we'll need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Files we need:\n",
    "#Training data matrix\n",
    "train_data = pd.read_table(\"newsgroups/trainMatrixModified.txt\", header=None)\n",
    "\n",
    "#Training labels\n",
    "train_labels = pd.read_table(\"newsgroups/trainClasses.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "      <th>799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   790  791  792  793  \\\n",
       "0  2.0  0.0  0.0  2.0  2.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  3.0  0.0   \n",
       "2  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
       "4  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  2.0  0.0   \n",
       "\n",
       "   794  795  796  797  798  799  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape: (5500, 800)\n"
     ]
    }
   ],
   "source": [
    "#training data shape\n",
    "print(\"DF shape: {}\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  0\n",
       "1  1  1\n",
       "2  2  0\n",
       "3  3  1\n",
       "4  4  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1\n",
       "0   0\n",
       "1   1\n",
       "2   0\n",
       "3   1\n",
       "4   0\n",
       "5   1\n",
       "6   1\n",
       "7   1\n",
       "8   1\n",
       "9   1\n",
       "10  1\n",
       "11  0\n",
       "12  0\n",
       "13  1\n",
       "14  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the first column of the training labels\n",
    "train_labels.drop(0, axis=1, inplace=True)\n",
    "train_labels.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5490</th>\n",
       "      <th>5491</th>\n",
       "      <th>5492</th>\n",
       "      <th>5493</th>\n",
       "      <th>5494</th>\n",
       "      <th>5495</th>\n",
       "      <th>5496</th>\n",
       "      <th>5497</th>\n",
       "      <th>5498</th>\n",
       "      <th>5499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   5490  \\\n",
       "0   2.0   2.0   2.0   1.0   8.0   6.0   2.0   8.0   2.0   4.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   1.0   0.0   0.0   0.0   2.0   0.0   1.0  ...    0.0   \n",
       "3   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   5491  5492  5493  5494  5495  5496  5497  5498  5499  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5500 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rotate the training data to be a document-term matrix:\n",
    "train_data_docterm = train_data.T\n",
    "train_data_docterm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['david', 'rex', 'wood', 'subject', 'call', 'librari', 'creat',\n",
       "       'widget', 'multipl', 'time', 'dai', 'ago', 'post', 'question',\n",
       "       'try', 'function', 'set', 'app', 'point', 'xtappiniti', 'help',\n",
       "       'have', 'problem', 'littl', 'test', 'program', 'close', 'model',\n",
       "       'real', 'actual'], \n",
       "      dtype='<U79')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bring in the vocabulary of terms\n",
    "terms = np.genfromtxt(\"newsgroups/modifiedterms.txt\", dtype=str)\n",
    "terms[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze term frequency by forming a dictionary of terms and their counts in the document-term matrix (ie columns of the DF). See [example](http://facweb.cs.depaul.edu/mobasher/classes/csc478/Notes/IPython%20Notebook%20-%20Term-Doc-KNN.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00', 159.0), ('10', 254.0), ('1010', 105.0), ('125', 74.0), ('14', 100.0), ('1990', 73.0), ('1991', 159.0), ('1992', 23.0), ('1993', 80.0), ('1st', 67.0), ('20', 32.0), ('21', 61.0), ('25', 136.0), ('2nd', 24.0), ('30', 59.0), ('4324219', 24.0), ('50', 78.0), ('5000', 286.0), ('63', 44.0), ('635', 42.0), ('705', 78.0), ('89', 204.0), ('919', 113.0), ('999', 32.0), ('abc', 172.0), ('abl', 73.0), ('accept', 195.0), ('access', 53.0), ('act', 168.0), ('activ', 107.0), ('actual', 485.0), ('adam', 81.0), ('add', 205.0), ('addit', 53.0), ('address', 31.0), ('admit', 81.0), ('admittedli', 202.0), ('advanc', 125.0), ('advantag', 45.0), ('advic', 75.0), ('afternoon', 102.0), ('ago', 78.0), ('allstar', 47.0), ('altern', 2.0), ('amount', 330.0), ('analyst', 51.0), ('anderson', 99.0), ('andrewcmuedu', 28.0), ('angel', 253.0), ('angelo', 72.0), ('announc', 48.0), ('anonym', 28.0), ('anybodi', 89.0), ('anymor', 89.0), ('anywai', 792.0), ('app', 50.0), ('appear', 214.0), ('appropri', 74.0), ('archiv', 169.0), ('area', 109.0), ('argument', 7.0), ('arrang', 2754.0), ('articl', 75.0), ('audett', 59.0), ('automat', 79.0), ('avail', 51.0), ('averag', 28.0), ('awai', 41.0), ('back', 22.0), ('bad', 89.0), ('bai', 97.0), ('baker', 119.0), ('balanc', 50.0), ('base', 108.0), ('basic', 114.0), ('bassen', 66.0), ('beat', 109.0), ('behind', 96.0), ('belfour', 79.0), ('bell', 23.0), ('berth', 142.0), ('best', 44.0), ('better', 122.0), ('biggest', 48.0), ('bill', 29.0), ('binari', 45.0), ('blackhawk', 57.0), ('blame', 45.0), ('blow', 82.0), ('blown', 225.0), ('blue', 110.0), ('bodi', 43.0), ('bondra', 72.0), ('bonehead', 35.0), ('boora', 79.0), ('boston', 59.0), ('boulder', 48.0), ('bounc', 46.0), ('bourqu', 244.0), ('box', 39.0), ('bradlei', 27.0), ('brian', 99.0), ('broadcast', 67.0), ('broten', 84.0), ('brought', 51.0), ('bruin', 74.0), ('brutal', 104.0), ('bryan', 49.0), ('buchberg', 67.0), ('buffalo', 80.0), ('buffer', 53.0), ('bure', 209.0), ('busi', 40.0), ('button', 11.0), ('calgari', 58.0), ('call', 33.0), ('canada', 55.0), ('canadian', 40.0), ('canadien', 1465.0), ('canuck', 49.0), ('cap', 75.0), ('capit', 89.0), ('care', 180.0), ('carri', 49.0), ('cassel', 76.0), ('caught', 48.0), ('cbc', 145.0), ('ccdb', 126.0), ('cha', 75.0), ('chaisson', 55.0), ('champion', 53.0), ('chanc', 102.0), ('chang', 88.0), ('cheap', 82.0), ('cheaper', 82.0), ('check', 101.0), ('chest', 49.0), ('chicago', 50.0), ('choic', 70.0), ('chri', 219.0), ('class', 105.0), ('clement', 51.0), ('click', 40.0), ('close', 32.0), ('closer', 127.0), ('coach', 13.0), ('code', 55.0), ('colorado', 190.0), ('come', 6.0), ('comeback', 48.0), ('command', 90.0), ('competit', 127.0), ('compil', 115.0), ('conach', 113.0), ('connect', 74.0), ('content', 93.0), ('contribut', 93.0), ('contributor', 71.0), ('control', 434.0), ('convent', 68.0), ('cote', 116.0), ('cours', 52.0), ('cover', 38.0), ('creat', 119.0), ('creighton', 56.0), ('crosscheck', 46.0), ('cscoloradoedu', 86.0), ('cup', 32.0), ('current', 14.0), ('cut', 48.0), ('dahlquist', 139.0), ('dai', 109.0), ('dan', 102.0), ('date', 60.0), ('david', 196.0), ('davidson', 228.0), ('dead', 34.0), ('dec', 39.0), ('decis', 59.0), ('decstat', 75.0), ('decwindow', 52.0), ('deep', 32.0), ('defens', 44.0), ('demand', 134.0), ('demer', 90.0), ('demo', 87.0), ('demonstr', 48.0), ('deni', 132.0), ('denni', 22.0), ('desktop', 200.0), ('desper', 93.0), ('despit', 171.0), ('detroit', 123.0), ('devil', 46.0), ('dg', 140.0), ('di', 14.0), ('differ', 110.0), ('difficulti', 73.0), ('disappoint', 94.0), ('discuss', 58.0), ('displai', 68.0), ('divis', 51.0), ('domin', 45.0), ('done', 25.0), ('donnelli', 87.0), ('doubl', 66.0), ('doublehead', 115.0), ('doubt', 130.0), ('dress', 47.0), ('drop', 109.0), ('druce', 67.0), ('dsweenei', 356.0), ('due', 121.0), ('dump', 34.0), ('easili', 142.0), ('east', 513.0), ('ed', 32.0), ('edit', 86.0), ('edmonton', 25.0), ('eklund', 28.0), ('elbow', 243.0), ('ellett', 119.0), ('elynuik', 14.0), ('email', 141.0), ('encourag', 127.0), ('end', 60.0), ('enjoi', 29.0), ('entertain', 15.0), ('error', 69.0), ('especi', 62.0), ('espn', 69.0), ('establish', 12.0), ('event', 68.0), ('everyon', 37.0), ('everyth', 103.0), ('exampl', 162.0), ('except', 36.0), ('exit', 134.0), ('expect', 167.0), ('explor', 34.0), ('extens', 67.0), ('fact', 55.0), ('fail', 45.0), ('fan', 220.0), ('faq', 20.0), ('far', 78.0), ('fat', 64.0), ('fax', 151.0), ('fedyk', 72.0), ('feed', 115.0), ('felt', 30.0), ('figur', 94.0), ('file', 41.0), ('final', 57.0), ('finish', 38.0), ('first', 32.0), ('five', 28.0), ('fix', 220.0), ('flame', 104.0), ('fleuri', 97.0), ('flyer', 52.0), ('folk', 124.0), ('follow', 115.0), ('forget', 68.0), ('form', 70.0), ('format', 135.0), ('former', 54.0), ('forum', 118.0), ('freenetcarletonca', 113.0), ('frustrat', 33.0), ('ftp', 74.0), ('fuhr', 30.0), ('fulli', 26.0), ('fun', 28.0), ('function', 94.0), ('gallei', 52.0), ('game', 28.0), ('gari', 48.0), ('gaudreau', 64.0), ('gaussmedharvardedu', 35.0), ('gener', 56.0), ('get', 269.0), ('ghostscript', 29.0), ('gibson', 35.0), ('gilmour', 114.0), ('give', 76.0), ('given', 175.0), ('glenn', 28.0), ('gnu', 103.0), ('go', 197.0), ('goal', 112.0), ('goaltend', 100.0), ('godfath', 72.0), ('goe', 705.0), ('good', 113.0), ('got', 25.0), ('gotta', 93.0), ('goulet', 82.0), ('grab', 25.0), ('grant', 54.0), ('great', 38.0), ('gretzki', 123.0), ('group', 215.0), ('guess', 33.0), ('gui', 536.0), ('hab', 87.0), ('half', 74.0), ('hardli', 127.0), ('harri', 27.0), ('hartford', 55.0), ('hatcher', 77.0), ('have', 142.0), ('hawk', 53.0), ('head', 17.0), ('header', 73.0), ('headlin', 111.0), ('healthyuwaterlooca', 119.0), ('heck', 30.0), ('hei', 520.0), ('height', 72.0), ('help', 16.0), ('hextal', 90.0), ('hi', 84.0), ('hierarchi', 199.0), ('highstick', 119.0), ('histori', 48.0), ('hit', 293.0), ('hockei', 4367.0), ('hope', 50.0), ('host', 26.0), ('hot', 140.0), ('hrudei', 59.0), ('hsdndevharvardedu', 68.0), ('ic', 124.0), ('icon', 27.0), ('idea', 2715.0), ('imho', 102.0), ('impal', 254.0), ('impress', 137.0), ('improv', 337.0), ('includ', 124.0), ('inclus', 88.0), ('increas', 57.0), ('inform', 45.0), ('initi', 69.0), ('insert', 49.0), ('instal', 70.0), ('institut', 248.0), ('int', 35.0), ('integr', 55.0), ('interact', 94.0), ('interfac', 25.0), ('internet', 26.0), ('involv', 78.0), ('ipc', 82.0), ('isl', 122.0), ('island', 73.0), ('jacqu', 134.0), ('jagr', 48.0), ('jbrown', 95.0), ('jersei', 20.0), ('jet', 31.0), ('johansson', 64.0), ('john', 76.0), ('jose', 111.0), ('june', 71.0), ('just', 94.0), ('keep', 26.0), ('kept', 183.0), ('kick', 41.0), ('king', 17.0), ('kisio', 66.0), ('kitssfuca', 297.0), ('know', 54.0), ('kovalenko', 161.0), ('kovalev', 61.0), ('kozlov', 70.0), ('la', 32.0), ('laboratori', 49.0), ('lack', 148.0), ('ladi', 31.0), ('lafontain', 119.0), ('lead', 106.0), ('leadership', 63.0), ('leaf', 45.0), ('least', 61.0), ('lebeau', 44.0), ('left', 206.0), ('lemieux', 47.0), ('level', 431.0), ('lib', 236.0), ('librari', 245.0), ('linden', 144.0), ('lindro', 53.0), ('line', 35.0), ('link', 216.0), ('list', 13.0), ('littl', 33.0), ('lo', 96.0), ('load', 47.0), ('local', 17.0), ('long', 57.0), ('look', 36.0), ('lose', 73.0), ('loss', 310.0), ('lost', 37.0), ('loui', 135.0), ('love', 92.0), ('maciv', 68.0), ('maclean', 44.0), ('magazin', 447.0), ('mail', 195.0), ('main', 70.0), ('major', 47.0), ('makarov', 75.0), ('manag', 131.0), ('manson', 40.0), ('mapl', 31.0), ('mark', 168.0), ('match', 110.0), ('mclean', 66.0), ('mean', 98.0), ('mechan', 44.0), ('mee', 45.0), ('mellanbi', 105.0), ('member', 28.0), ('mention', 161.0), ('messag', 143.0), ('messier', 87.0), ('min', 44.0), ('mind', 33.0), ('minnesota', 11.0), ('minor', 36.0), ('minut', 49.0), ('misconduct', 9.0), ('miss', 185.0), ('mit', 58.0), ('mo', 778.0), ('modano', 16.0), ('model', 58.0), ('moder', 4.0), ('mogilni', 56.0), ('momesso', 22.0), ('montreal', 129.0), ('moog', 217.0), ('morn', 46.0), ('move', 136.0), ('muller', 64.0), ('multipl', 62.0), ('musicamcgillca', 19.0), ('mvp', 98.0), ('name', 47.0), ('nation', 42.0), ('natur', 28.0), ('ncd', 46.0), ('necessarili', 58.0), ('nedv', 17.0), ('need', 357.0), ('neglect', 244.0), ('network', 21.0), ('new', 14.0), ('newsdisplai', 27.0), ('newsgroup', 42.0), ('newspap', 118.0), ('nhl', 205.0), ('nhma', 24.0), ('night', 95.0), ('nord', 227.0), ('nordiqu', 40.0), ('north', 31.0), ('noth', 302.0), ('notic', 82.0), ('null', 128.0), ('ny', 68.0), ('oat', 70.0), ('observ', 101.0), ('obtain', 195.0), ('odd', 63.0), ('offenc', 61.0), ('offens', 70.0), ('offer', 56.0), ('oh', 303.0), ('oiler', 187.0), ('ok', 28.0), ('okai', 57.0), ('old', 203.0), ('on', 81.0), ('ontario', 151.0), ('open', 60.0), ('opinion', 51.0), ('opportun', 24.0), ('option', 64.0), ('ot', 26.0), ('ottawa', 173.0), ('outlin', 74.0), ('output', 31.0), ('outset', 75.0), ('outsid', 65.0), ('pair', 55.0), ('particip', 172.0), ('particular', 35.0), ('past', 152.0), ('pat', 27.0), ('patch', 57.0), ('pathet', 68.0), ('patrick', 177.0), ('paul', 72.0), ('pearson', 95.0), ('pen', 21.0), ('penalti', 63.0), ('penguin', 50.0), ('peopl', 89.0), ('perform', 27.0), ('period', 13.0), ('petit', 55.0), ('pgh', 91.0), ('philadelphia', 21.0), ('phone', 17.0), ('physic', 67.0), ('pick', 217.0), ('pie', 40.0), ('pine', 40.0), ('pittsburgh', 61.0), ('place', 58.0), ('plai', 47.0), ('plan', 30.0), ('player', 68.0), ('playoff', 44.0), ('pleas', 31.0), ('pleshar', 99.0), ('plu', 109.0), ('po', 28.0), ('point', 132.0), ('polici', 72.0), ('possibl', 71.0), ('post', 413.0), ('postscript', 65.0), ('potvin', 29.0), ('ppv', 17.0), ('previou', 84.0), ('printf', 366.0), ('probabl', 108.0), ('problem', 21.0), ('procedur', 15.0), ('product', 3740.0), ('prog', 25.0), ('program', 89.0), ('programm', 62.0), ('propag', 116.0), ('proper', 70.0), ('prove', 154.0), ('provid', 298.0), ('psuvmpsuedu', 71.0), ('publish', 135.0), ('pull', 73.0), ('punch', 69.0), ('put', 55.0), ('quebec', 127.0), ('question', 95.0), ('r4', 226.0), ('r5', 36.0), ('rais', 42.0), ('ralph', 182.0), ('ranger', 43.0), ('rap115', 19.0), ('reader', 105.0), ('real', 51.0), ('realli', 48.0), ('recchi', 1051.0), ('receiv', 131.0), ('record', 54.0), ('recov', 68.0), ('red', 232.0), ('reichel', 318.0), ('rel', 101.0), ('relat', 33.0), ('rememb', 147.0), ('repres', 155.0), ('request', 25.0), ('requir', 31.0), ('resembl', 60.0), ('resourc', 92.0), ('respect', 13.0), ('respond', 63.0), ('rest', 33.0), ('return', 64.0), ('rex', 79.0), ('ricci', 133.0), ('right', 101.0), ('ring', 77.0), ('rm', 268.0), ('robbi', 101.0), ('robert', 38.0), ('robitail', 121.0), ('roenick', 22.0), ('roger', 46.0), ('roi', 46.0), ('ron', 78.0), ('room', 57.0), ('rose', 36.0), ('round', 122.0), ('rout', 81.0), ('rp16', 24.0), ('rub', 37.0), ('run', 52.0), ('rush', 129.0), ('ruuttu', 130.0), ('rychel', 27.0), ('sa', 94.0), ('sabr', 115.0), ('sai', 29.0), ('sakic', 44.0), ('san', 57.0), ('sanderson', 62.0), ('saturdai', 66.0), ('savard', 37.0), ('save', 46.0), ('saw', 117.0), ('schedul', 24.0), ('sco', 93.0), ('score', 155.0), ('scott', 7.0), ('screen', 17.0), ('screw', 54.0), ('season', 77.0), ('second', 109.0), ('see', 86.0), ('seen', 187.0), ('selann', 27.0), ('select', 107.0), ('semak', 31.0), ('semi', 194.0), ('senat', 34.0), ('send', 174.0), ('sergei', 235.0), ('seri', 237.0), ('seriou', 128.0), ('serv', 123.0), ('set', 49.0), ('setup', 58.0), ('sfuca', 80.0), ('shanahan', 157.0), ('shark', 92.0), ('shift', 156.0), ('shneyder', 36.0), ('shot', 268.0), ('show', 57.0), ('similarli', 160.0), ('sit', 71.0), ('site', 48.0), ('sleep', 101.0), ('smale', 43.0), ('softwar', 32.0), ('someth', 62.0), ('sourc', 30.0), ('southern', 93.0), ('speak', 86.0), ('specif', 86.0), ('st', 78.0), ('stanlei', 146.0), ('star', 47.0), ('start', 84.0), ('static', 3468.0), ('stdioh', 94.0), ('steven', 38.0), ('stloui', 96.0), ('straight', 42.0), ('stride', 30.0), ('strong', 66.0), ('stronger', 99.0), ('strongli', 109.0), ('stuff', 5.0), ('subject', 39.0), ('submiss', 80.0), ('subscrib', 34.0), ('subscript', 74.0), ('suggest', 25.0), ('summer', 216.0), ('sun', 191.0), ('sundai', 39.0), ('superiorcarletonca', 166.0), ('support', 28.0), ('surpris', 32.0), ('suspens', 82.0), ('suter', 124.0), ('sutter', 105.0), ('symasussexacuk', 60.0), ('system', 194.0), ('take', 1464.0), ('talent', 91.0), ('tampa', 60.0), ('team', 41.0), ('technolog', 770.0), ('tee', 128.0), ('tell', 41.0), ('term', 1702.0), ('termin', 16.0), ('test', 94.0), ('thank', 46.0), ('thing', 41.0), ('think', 57.0), ('third', 41.0), ('thorn', 52.0), ('thought', 42.0), ('three', 49.0), ('thursdai', 97.0), ('time', 219.0), ('tocchet', 23.0), ('todai', 55.0), ('told', 55.0), ('tom', 21.0), ('tonight', 199.0), ('top', 15.0), ('toronto', 43.0), ('total', 85.0), ('tough', 31.0), ('tree', 87.0), ('tri', 194.0), ('troubl', 136.0), ('truli', 61.0), ('try', 51.0), ('tuesdai', 56.0), ('turgeon', 22.0), ('tv', 187.0), ('twm', 131.0), ('two', 143.0), ('unabl', 132.0), ('unfortun', 25.0), ('univers', 152.0), ('unix', 39.0), ('unusu', 104.0), ('upcom', 162.0), ('updat', 159.0), ('us', 6.0), ('usenet', 122.0), ('usual', 99.0), ('uucp', 145.0), ('uunetuunet', 98.0), ('vacat', 257.0), ('valuabl', 49.0), ('vancouv', 34.0), ('var', 180.0), ('variabl', 21.0), ('variant', 84.0), ('vaxcnsmuskingumedu', 28.0), ('vernon', 47.0), ('view', 83.0), ('vlad', 101.0), ('vladimir', 63.0), ('void', 55.0), ('vzhivov', 145.0), ('wai', 75.0), ('wait', 74.0), ('want', 40.0), ('warren', 27.0), ('washington', 54.0), ('watch', 31.0), ('wednesdai', 60.0), ('weight', 121.0), ('welcom', 66.0), ('went', 111.0), ('weslei', 258.0), ('west', 213.0), ('whaler', 62.0), ('widget', 55.0), ('win', 51.0), ('window', 106.0), ('wing', 64.0), ('winnipeg', 180.0), ('wm', 154.0), ('wood', 51.0), ('word', 40.0), ('work', 50.0), ('worldwid', 50.0), ('worst', 77.0), ('write', 82.0), ('writer', 38.0), ('wrong', 14.0), ('wrote', 129.0), ('x11', 37.0), ('x11r5', 61.0), ('xdm', 125.0), ('xevent', 53.0), ('xlibh', 47.0), ('xm', 168.0), ('xmh', 665.0), ('xtappcontext', 73.0), ('xtappiniti', 90.0), ('xtdestroywidget', 85.0), ('xtdispatchev', 89.0), ('xterm', 1477.0), ('xtermin', 64.0), ('xtrealizewidget', 95.0), ('xtvacreatemanagedwidget', 108.0), ('yawnei', 42.0), ('year', 92.0), ('york', 34.0), ('yzerman', 38.0), ('zhivov', 183.0), ('zone', 51.0)]\n"
     ]
    }
   ],
   "source": [
    "termFreqs = train_data_docterm.sum(axis=1)\n",
    "\n",
    "dictTF = {}\n",
    "for i in range(len(termFreqs)):\n",
    "    dictTF[terms[i]] = termFreqs[i]\n",
    "print(sorted(dictTF.items()))\n",
    "sortedTF = sorted(dictTF.values(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHc5JREFUeJzt3X+QVeWd5/H3hx8NjSIhUSABfw5iMJUEyYYk62553Uzw\nR6rEyky5TLJRo9akFNdUrMoGkpqia2pqJ25NHGdqVqcyZgMkZglmNwFrGBSCN7OTKoVEEBSUTgxI\nM9LqGH/ys+W7f5znpg/NbfpCX849TX9eVafuuc89957v7Yb+3Od5zrlHEYGZmdmIVhdgZmbl4EAw\nMzPAgWBmZokDwczMAAeCmZklDgQzMwNOIBAkjZC0SdKqdH+xpC5JT6Xl6ty2iyR1StouaW6ufbak\nLZJ2SLqvuW/FzMwG40R6CF8Bnu3Tdm9EzE7LGgBJM4EbgJnANcD9kpS2fwC4NSJmADMkXTW48s3M\nrFkaCgRJ04BrgQf7PlRn83nA8ojoiYidQCcwR9IUYHxEbEzbLQOuP6mqzcys6RrtIfw18DWg72nN\nd0raLOlBSRNS21Rgd26bPaltKtCVa+9KbWZmVgIDBoKkzwLdEbGZo3sE9wMXRcQsYC/w7VNTopmZ\nFWFUA9tcDlwn6VqgHRgvaVlE3Jjb5h+AR9L6HuDc3GPTUlt/7ceQ5C9YMjM7CRFRbyi/IQP2ECLi\nGxFxXkRcBMwH1kfEjWlOoOZzwDNpfRUwX1KbpAuB6cCGiNgLvCFpTppkvhFYeZz9ln5ZvHhxy2s4\nHWp0na6z7MtQqXOwGukh9Od/SJoFHAF2Al9Of8i3SVoBbAMOA3dEb6ULgCXAWGB1pCOTzMys9U4o\nECLi58DP0/qNx9nuL4G/rNP+K+DDJ1ijmZkVwGcqD0KlUml1CQMaCjWC62w219lcQ6XOwVIzxp2a\nTVKUsS4zszKTRJzKSWUzMxseHAhmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZoADwczMEgeCmZkBDgQz\nM0scCGZmBjgQzMwscSCYmRngQDAzs8SBYGZmwAkEgqQRkp6StCrdnyjpMUnPS3pU0oTctoskdUra\nLmlurn22pC2Sdki6r7lvxczMBuNEeghfIbssZs1CYF1EXAKsBxYBSLoUuAGYCVwD3J+uoQzwAHBr\nRMwAZki6apD1m5lZkzQUCJKmAdcCD+aa5wFL0/pS4Pq0fh2wPCJ6ImIn0AnMkTQFGB8RG9N2y3LP\nMTOzFmu0h/DXwNeA/GXMJkdEN0BE7AUmpfapwO7cdntS21SgK9feldrMzKwERg20gaTPAt0RsVlS\n5TibNvWalx0dHb9fr1Qqw+aapmZmjapWq1Sr1aa93oDXVJb034H/AvQA7cB44CfAvwMqEdGdhoMe\nj4iZkhYCERH3pOevARYDu2rbpPb5wBURcXudffqaymZmJ+iUX1M5Ir4REedFxEXAfGB9RHwReAS4\nOW12E7Ayra8C5ktqk3QhMB3YkIaV3pA0J00y35h7jpmZtdiAQ0bH8S1ghaRbyD793wAQEdskrSA7\nIukwcEfu4/4CYAkwFlgdEWsGsX8zM2uiAYeMWsFDRmZmJ+6UDxmZmdnw4EAwMzPAgWBmZokDwczM\nAAeCmZklDgQzMwMcCGZmljgQzMwMcCCYmVniQDAzM8CBYGZmiQPBzMwAB4KZmSUOBDMzAxwIZmaW\nOBDMzAxoIBAkjZH0pKRNkrZKWpzaF0vqkvRUWq7OPWeRpE5J2yXNzbXPlrRF0g5J952at2RmZiej\noSumSRoXEfskjQR+AdwFXAO8FRH39tl2JvBD4OPANGAdcHFEhKQngTsjYqOk1cDfRMSjdfbnK6aZ\nmZ2gQq6YFhH70uoYsusw1/5a19vxPGB5RPRExE6gE5gjaQowPiI2pu2WAdefbOFmZtZcDQWCpBGS\nNgF7gbW5P+p3Stos6UFJE1LbVGB37ul7UttUoCvX3pXazMysBEY1slFEHAEuk3QW8BNJlwL3A3+e\nhoL+Avg2cFuzClu8uAOl/kelUqFSqTTrpc3MTgvVapVqtdq012toDuGoJ0h/BryTnzuQdD7wSER8\nRNJCICLinvTYGmAxsAt4PCJmpvb5wBURcXudfcSBA8GYMSf7tszMhp9TPocg6ezacJCkduAzwHNp\nTqDmc8AzaX0VMF9Sm6QLgenAhojYC7whaY4kATcCK/vbb0/PSb0fMzM7SY0MGb0fWCppBFmA/Cgi\nVktaJmkWcATYCXwZICK2SVoBbAMOA3fkDhlaACwBxgKrI2JNfzt9992Te0NmZnZyTnjIqAiS4rXX\ngokTW12JmdnQUchhp63gHoKZWbEcCGZmBjgQzMwscSCYmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEO\nBDMzSxwIZmYGlDgQ/OV2ZmbFKm0guIdgZlYsB4KZmQEOBDMzSxwIZmYGOBDMzCxp5BKaYyQ9KWmT\npK2SFqf2iZIek/S8pEdrl9lMjy2S1Clpu6S5ufbZkrZI2iHpvuPt14FgZlasAQMhIg4CV0bEZcAs\n4BpJc4CFwLqIuARYDywCkHQpcAMwE7gGuD9dQxngAeDWiJgBzJB0VX/7dSCYmRWroSGjiNiXVseQ\nXYc5gHnA0tS+FLg+rV8HLI+InojYCXQCcyRNAcZHxMa03bLcc47hQDAzK1ZDgSBphKRNwF5gbfqj\nPjkiugEiYi8wKW0+Fdide/qe1DYV6Mq1d6W2uhwIZmbFGtXIRhFxBLhM0lnATyR9iKyXcNRmzSzs\noYc6eOqpbL1SqVCpVJr58mZmQ161WqVarTbt9RRxYn/HJf0ZsA+4DahERHcaDno8ImZKWghERNyT\ntl8DLAZ21bZJ7fOBKyLi9jr7iIcfDv74jwfz1szMhhdJRIQG3rK+Ro4yOrt2BJGkduAzwHZgFXBz\n2uwmYGVaXwXMl9Qm6UJgOrAhDSu9IWlOmmS+MfecY3jIyMysWI0MGb0fWCppBFmA/CgiVkt6Algh\n6RayT/83AETENkkrgG3AYeCO6O2GLACWAGOB1RGxpr+dOhDMzIp1wkNGRZAUy5YFX/xiqysxMxs6\nTvmQUau4h2BmViwHgpmZAQ4EMzNLHAhmZgY4EMzMLHEgmJkZ4EAwM7OktIHQ3d3qCszMhpfSBsKG\nDa2uwMxseCltILzwQqsrMDMbXkobCCX8Rg0zs9NaaQPBk8pmZsUqbSAcOdLqCszMhhcHgpmZAQ4E\nMzNLGrli2jRJ6yU9K2mrpP+a2hdL6pL0VFquzj1nkaROSdslzc21z5a0RdIOSfcdb78OBDOzYjVy\nxbQe4O6I2CzpTOBXktamx+6NiHvzG0uaSXb1tJnANGCdpIvTVdMeAG6NiI2SVku6KiIerbdTB4KZ\nWbEG7CFExN6I2JzW3ya7nvLU9HC9K/PMA5ZHRE9E7AQ6gTmSpgDjI2Jj2m4ZcH1/+3UgmJkV64Tm\nECRdAMwCnkxNd0raLOlBSRNS21Rgd+5pe1LbVKAr195Fb7Acw4edmpkVq+FASMNFPwa+knoK9wMX\nRcQsYC/w7WYW5h6CmVmxGplDQNIosjD4fkSsBIiIV3Kb/APwSFrfA5ybe2xaauuvva5Dhzro6MjW\nK5UKlUqlkVLNzIaNarVKtVpt2uspGviOCEnLgFcj4u5c25SI2JvWvwp8PCI+L+lS4CHgE2RDQmuB\niyMiJD0B3AVsBP4R+NuIWFNnfzF6dHDo0ODfoJnZcCGJiKg3t9uQAXsIki4HvgBslbQJCOAbwOcl\nzQKOADuBLwNExDZJK4BtwGHgjuhNnQXAEmAssLpeGNR4yMjMrFgN9RCKJimkcCiYmZ2AwfYQSnum\ncoS/8dTMrEilDQTJgWBmVqTSBsKIET4XwcysSKUOBM8hmJkVp7SBMHKkA8HMrEilDQT3EMzMiuVA\nMDMzwIFgZmaJA8HMzAAHgpmZJaUOBJ+HYGZWnNIGgg87NTMrVmkDwUNGZmbFciCYmRngQDAzs8SB\nYGZmQAOBIGmapPWSnpW0VdJdqX2ipMckPS/pUUkTcs9ZJKlT0nZJc3PtsyVtkbRD0n3HLcyBYGZW\nqEZ6CD3A3RHxIeBTwAJJHwQWAusi4hJgPbAIIF1T+QZgJnANcL+k2hV8HgBujYgZwAxJV/VbmA87\nNTMr1ICBEBF7I2JzWn8b2A5MA+YBS9NmS4Hr0/p1wPKI6ImInUAnMEfSFGB8RGxM2y3LPefYwtxD\nMDMr1AnNIUi6AJgFPAFMjohuyEIDmJQ2mwrszj1tT2qbCnTl2rtSW10+D8HMrFgNB4KkM4EfA19J\nPYW+F7hs6gUv3UMwMyvWqEY2kjSKLAy+HxErU3O3pMkR0Z2Gg15O7XuAc3NPn5ba+muv65VXOvi7\nv4PJk6FSqVCpVBp6Q2Zmw0W1WqVarTbt9RQNXMle0jLg1Yi4O9d2D/BaRNwj6evAxIhYmCaVHwI+\nQTYktBa4OCJC0hPAXcBG4B+Bv42INXX2Fx/5SLBsGXz0o014l2Zmw4AkIkIDb1nfgD0ESZcDXwC2\nStpENjT0DeAeYIWkW4BdZEcWERHbJK0AtgGHgTuiN3UWAEuAscDqemFQ4yEjM7NiNdRDKJqkmD07\n+M534GMfa3U1ZmZDw2B7CKU+U9nnIZiZFafUgeAhIzOz4pQ2EHwegplZsUobCO4hmJkVy4FgZmaA\nA8HMzBIHgpmZAQ4EMzNLSh0IPg/BzKw4pQ0EH3ZqZlasUgdCT0+rqzAzGz5KGwjt7bB/f6urMDMb\nPkobCOPGORDMzIpU2kBob4d9+1pdhZnZ8FHaQHAPwcysWKUNBPcQzMyKNWAgSPqupG5JW3JtiyV1\nSXoqLVfnHlskqVPSdklzc+2zJW2RtEPSfQPtd9w4B4KZWZEa6SF8D7iqTvu9ETE7LWsAJM0ku5Tm\nTOAa4H5Jtav3PADcGhEzgBmS6r3m7/koIzOzYg0YCBHxL8Dv6jxU7zJt84DlEdETETuBTmCOpCnA\n+IjYmLZbBlx/vP26h2BmVqzBzCHcKWmzpAclTUhtU4HduW32pLapQFeuvSu19cuBYGZWrFEn+bz7\ngT+PiJD0F8C3gduaVxY88kgHzz4LHR1QqVSoVCrNfHkzsyGvWq1SrVab9nqKiIE3ks4HHomIjxzv\nMUkLgYiIe9Jja4DFwC7g8YiYmdrnA1dExO397C/WrQtuvx1+9jM499yTfXtmZsOHJCKi3nB+Qxod\nMhK5OYM0J1DzOeCZtL4KmC+pTdKFwHRgQ0TsBd6QNCdNMt8IrDzeDq+8Es4+G+4b8HgkMzNrhgGH\njCT9EKgA75P0Itkn/islzQKOADuBLwNExDZJK4BtwGHgjujtgiwAlgBjgdW1I5P6M2IEzJ8PnZ0n\n8a7MzOyENTRkVDRJERE88AA8/TT8/d+3uiIzs/IrasioJUaPhsOHW12FmdnwUOpAaGtzIJiZFaXU\ngTB6NBw61OoqzMyGh9IHgnsIZmbFcCCYmRngQDAzs6TUgdDW5jkEM7OilDoQ3EMwMyuOA8HMzAAH\ngpmZJaUOBM8hmJkVp9SB4B6CmVlxHAhmZgY4EMzMLHEgmJkZUPJA8KSymVlxBgwESd+V1C1pS65t\noqTHJD0v6VFJE3KPLZLUKWm7pLm59tmStkjaIamhC2O6h2BmVpxGegjfA67q07YQWBcRlwDrgUUA\nki4FbgBmAtcA96drKAM8ANwaETOAGZL6vuYx/PXXZmbFGTAQIuJfgN/1aZ4HLE3rS4Hr0/p1wPKI\n6ImInUAnMEfSFGB8RGxM2y3LPadfY8fCwYNQwqt8mpmddk52DmFSRHQDRMReYFJqnwrszm23J7VN\nBbpy7V2p7bhGjoRRozxsZGZWhFFNep2mf4bv6OgAQIK1ayt89rOVZu/CzGxIq1arVKvVpr2eooHx\nGEnnA49ExEfS/e1AJSK603DQ4xExU9JCICLinrTdGmAxsKu2TWqfD1wREbf3s7+o1TVpEmzdCpMn\nD/atmpmd3iQRERp4y/oaHTJSWmpWATen9ZuAlbn2+ZLaJF0ITAc2pGGlNyTNSZPMN+aec1zt7XDg\nQINVmpnZSRtwyEjSD4EK8D5JL5J94v8W8LCkW8g+/d8AEBHbJK0AtgGHgTuitwuyAFgCjAVWR8Sa\nRgocO9aBYGZWhIaGjIqWHzKaNQuWLMluzcysf0UNGbWMewhmZsVwIJiZGTAEAqG9Hfbvb3UVZman\nv9IHgnsIZmbFKH0g+LBTM7NilD4QJk6E559vdRVmZqe/0h92+pvfwKc+BT//Ocyc2eLCzMxK7LQ/\n7PQP/gCuuAKefrrVlZiZnd5KHwgAF14Iv/1tq6swMzu9DYlAuOgieOGFVldhZnZ6GxKB8OEPe8jI\nzOxUK/2kMsC+fXD22fD669DW1sLCzMxK7LSfVAYYNw4mTIBXXml1JWZmp68hEQiQnY/w+uutrsLM\n7PQ1pALhd79rdRVmZqcvB4KZmQGDDARJOyU9LWmTpA2pbaKkxyQ9L+lRSRNy2y+S1Clpu6S5J7Iv\nB4KZ2ak12B7CEaASEZdFxJzUthBYFxGXAOuBRQCSLiW71OZM4Brg/nR95YZ4DsHM7NQabCCozmvM\nA5am9aXA9Wn9OmB5RPRExE6gE5hDg2bOhNWroadncAWbmVl9gw2EANZK2ijpttQ2OSK6ASJiLzAp\ntU8Fdueeuye1NeRLX4LXXoMf/GCQFZuZWV2jBvn8yyPiJUnnAI9Jep4sJPJO6sy3jo6O369XKhUq\nlQp33gk//SncfPPJlmtmdvqoVqtUq9WmvV7TzlSWtBh4G7iNbF6hW9IU4PGImClpIRARcU/afg2w\nOCKerPNaUa+u3bvhYx+D7m5ofPbBzGx4aNmZypLGSTozrZ8BzAW2AquAm9NmNwEr0/oqYL6kNkkX\nAtOBDSeyz3PPzS6p+YtfnGzVZmbWn8EMGU0GfiIp0us8FBGPSfolsELSLcAusiOLiIhtklYA24DD\nwB11uwED+Ku/gmuvhe3bYWrDMxBmZjaQIfHldn396Z/CBz8Id99dYFFmZiU3LL7crq85c2DLllZX\nYWZ2ehmSgXDZZfCzn8Ezz7S6EjOz08eQDITZs+GWW2DePDhwoNXVmJmdHobkHAJABHz+89mZy8uX\nw8iRBRVnZlZSg51DGLKBALB/f3bE0f798IUvwI03ZhfSMTMbjoZ1IAAcPJidvfzjH8Ovfw0bN8Ko\nwZ5/bWY2BA37QKiJyHoL//zP8M1vZvMMV14JY8acoiLNzErGgdDHr34F3/sePP00PPccTJ8Of/RH\n8OlPw6xZ/soLMzt9ORCO48UXszOaH34YHn8cXn0VPv7x7KS2KVNgxoxsfcaM7CsxzMyGMgdCgyKy\nK66tWwd798JLL8GOHVlg7NoFF1wA55wD739/tkyZ0rt++eXQ3t7UcszMms6B0ARvvw07d2bfoloL\ni5deytZ37cqGod7znuy7k847D84/P7vNr59zjoejzKy1HAgFOHgwG27q6sq+gnvXrmw46sUXe9f3\n74dPfjILhrPPhkmTYPLk7Pacc3p7HGec0ep3Y2anKwdCSfzbv8GTT8Ibb2Th0d0NL7+c3b7ySm/P\no62td0jqrLPgzDOzwKgt48dnbRMmZI+3t2fzG2eckbW1tbX6nZpZWTkQhpAIeP31LBi6u+Gtt+DN\nN7MAefnl7Patt3rb33or63ns3w/vvJOFDfSGxLhxvetjxmT3J07MlnHjereZMCELmTFjskAZMyYL\nm/e+Nwua0aN7l7a2rM3BYzb0OBCGkQg4fLg3JGrLwYPZdzq9804WOK+9lrXX2t58M7s9eLB3efPN\nrFezb1/2mvnl7bezMBk//ugQaW/Plra23qUWRGPG9AbT+PFZ4IwenZ0kOHJktuTX86+XX8aMOTqc\n2tpgxJD8xi2z4g25QJB0NXAf2Rfrfbd2Sc0+2zgQWigiC4W33jo6RGoBdPgwHDqULQcOZKFSC6UD\nB7Lnvvlm9j1TPT3w7ru9t7X1gwez5x040Pu6tXA6dOjo2zFjjg6mWq9n7Nje8Bg1qjdEaqHVt+dz\n1llZ76cWSiNG9H87enT2OqNHHx1m+dvafuo9NmqUw8yKN6QCQdIIYAfwaeBfgY3A/Ih4rs92QyIQ\nqtUqlUql1WUc11CoEfqv88iRLDQOHeoNpn37suGzAweywOjp6b2tPd6313PoUG9P6ciRLJhqt/n1\n2m2tJ9Y31F5/vUp7e4Went799A292nMOHz46sGqhVQuLWuDUHssvtd5SPmDygTNuXPbcfIjl13fu\nrHLxxZVjwq3vfkaOzGoZOza7f7yQrN3Wtu+7z3r3Bzrybqj/+yybwQZC0d/6MwfojIhdAJKWA/OA\n5477rJIaCv9IhkKN0H+dI0Zkf/zGjSu+pno6Oqp0dFQa2jYiC6h8QNTWa72p2v38UgujQ4eODZn8\n47XHjhzJlsOHewNty5YqZ5xRqRtufV/z0KHs8f7Cse9trWcYcfT+89vVFjg6RPr2pt58s8o551QY\nNap3yLEWKvWW0aN7wzAfsLX1/GN9e2y1IK219w2wvm21IB05ElasqDJlSuWo2vLrtd5i/rGheBh6\n0YEwFdidu99FFhJmpx2pdWfAd3RkS6vVQqMWIn17UvfeCwsW9IbkoUO9wVRvOXw465n1DdhaT7A2\nDNk3RGs11IKxb4Dlg6y2ng/KvXth/fpjQ7O2n9pQaq0t4thgqwVWbW6sNpTZdz7trLOyQ9fz29TC\nqXawSHt7dkj7eedlRy026+v//b2gZnbKSEd/Ou/rve+FSy4pvq4TdaIBWwvC/FILmL7zZLV5uFqv\n8fXXswM+8kOd+Tm82rzbyy9n50G9+ip84ANw++2Df59FzyF8EuiIiKvT/YVA9J1YllT+CQQzsxIa\nSpPKI4HnySaVXwI2AH8SEdsLK8LMzOoqdMgoIt6VdCfwGL2HnToMzMxKoJQnppmZWfFKddqMpKsl\nPSdph6Svt7iW70rqlrQl1zZR0mOSnpf0qKQJuccWSeqUtF3S3ALrnCZpvaRnJW2VdFfZapU0RtKT\nkjalGheXrcY+9Y6Q9JSkVWWtU9JOSU+nn+mGEtc5QdLDab/PSvpE2eqUNCP9HJ9Kt29Iuqtsdab9\nflXSM5K2SHpIUltT64yIUixk4fRr4HxgNLAZ+GAL6/kPwCxgS67tHuC/pfWvA99K65cCm8iG4C5I\n70MF1TkFmJXWzySbo/lg2WoFxqXbkcATZIcbl6rGXK1fBX4ArCrx7/0FYGKftjLWuQT4UlofBUwo\nY525ekeQnTR7btnqBD6Qfu9t6f6PgJuaWWdhP+gG3uwngX/K3V8IfL3FNZ3P0YHwHDA5rU8BnqtX\nK/BPwCdaVPNPgT8sa63AOOCXwMfLWCMwDVgLVOgNhDLW+VvgfX3aSlUncBbwmzrtpaqzT21zgf9X\nxjrJAmEXMDH9kV/V7P/rZRoyqnfS2tQW1dKfSRHRDRARe4FJqb1v7XtoQe2SLiDr1TxB9g+kNLWm\nYZhNwF5gbURsLFuNyV8DXwPyk2tlrDOAtZI2SrqtpHVeCLwq6XtpOOY7ksaVsM68/wz8MK2Xqs6I\n+Ffg28CLaZ9vRMS6ZtZZpkAYikozIy/pTODHwFci4m2Ora2ltUbEkYi4jOwT+BxJH6pTU0trlPRZ\noDsiNgPHO5a7DL/3yyNiNnAtsEDSf6RkP0+yT7Gzgf+Zan2H7FNr2eoEQNJo4Drg4dRUqjolvYfs\nq37OJ+stnCHpC3XqOuk6yxQIe4DzcvenpbYy6ZY0GUDSFODl1L6HbMyxptDaJY0iC4PvR8TKMtca\nEW8CVeDqEtZ4OXCdpBeA/w38J0nfB/aWrE4i4qV0+wrZMOEcyvfz7AJ2R8Qv0/3/QxYQZauz5hrg\nVxHxarpftjr/EHghIl6LiHeBnwD/vpl1likQNgLTJZ0vqQ2YTzZG1kri6E+Kq4Cb0/pNwMpc+/w0\n438hMJ3spLui/C9gW0T8Ta6tNLVKOrt25IOkduAzwPYy1QgQEd+IiPMi4iKyf3/rI+KLwCNlqlPS\nuNQjRNIZZOPeWynfz7Mb2C1pRmr6NPBs2erM+ROyDwI1ZavzReCTksZKEtnPc1tT6yxywqaBSZOr\nyY6S6QQWtriWH5IdbXAw/SK+RDaZsy7V+Bjwntz2i8hm8bcDcwus83LgXbKjsjYBT6Wf43vLUivw\n4VTXZmAL8M3UXpoa69R8Bb2TyqWqk2xsvvb73lr7v1K2OtN+P0r2YW8z8H/JjjIqY53jgFeA8bm2\nMta5OO1zC7CU7IjMptXpE9PMzAwo15CRmZm1kAPBzMwAB4KZmSUOBDMzAxwIZmaWOBDMzAxwIJiZ\nWeJAMDMzAP4/+C4pSQhyDT8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(sortedTF)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a) Create a KNN classifier. \n",
    "It should allow as input the training data matrix, the training labels, the instance to be classified, the value of K. It should return the predicted classes for the instance, and the top K neighbors.  \n",
    "The classifier should work with Euclidean distance and Cosine Similarity. If necessary, can make 2 separate classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Items we need\n",
    "\n",
    "#training data matrix\n",
    "train_data_docterm = np.array(train_data_docterm)\n",
    "\n",
    "#training labels\n",
    "doc_labels_training = list(train_labels[1])\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (doc-term) dimensions: (800, 5500) \n",
      "Training labels is a list of length 800\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data (doc-term) dimensions: {} \\nTraining labels is a list of length {}\"\\\n",
    "      .format(train_data_docterm.shape, len(doc_labels_training)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function**  \n",
    "- Allows for both Euclidean distance and cosine similarity  \n",
    "- Returns predicted class (actual text, not coded binary) and term frequency of k-nearest neighbors (useful for inspection?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def knn_function(inX, dataSet, labels, k, measure):\n",
    "    #Find K nearest neighbors of the data among D\n",
    "    #Calculate the distance conditionally based on the measure given\n",
    "    if measure == 0:\n",
    "        dataSetSize = dataSet.shape[0]\n",
    "        #Instead of iterating for row vs row diff's, we can calculate the diff matrix at the array-level\n",
    "        diffMat = np.tile(inX, (dataSetSize,1)) - dataSet\n",
    "        sqDiffMat = diffMat**2\n",
    "        sqDistances = sqDiffMat.sum(axis=1)\n",
    "        distances = sqDistances**0.5\n",
    "\n",
    "    elif measure == 1:\n",
    "        D_norm = np.array([np.linalg.norm(dataSet[i]) for i in range(len(dataSet))])\n",
    "        x_norm = np.linalg.norm(inX)\n",
    "        cosines = np.dot(dataSet,inX)/(D_norm * x_norm)\n",
    "        distances = 1 - cosines\n",
    "    \n",
    "    #Once we have the distance, work on returning nearest neighbors\n",
    "    sortedDistIndicies = np.argsort(distances)\n",
    "    classCount={}\n",
    "    neighbor_idx = sortedDistIndicies[:k]\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    predicted_class = sortedClassCount[0][0]\n",
    "    return predicted_class, dataSet[neighbor_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A row from the training data\n",
    "vec_for_function = train_data_docterm[2]\n",
    "vec_for_function.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0 \n",
      " k-nearest neighbors:\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "predicted_class, k_neighbors = knn_function(vec_for_function, train_data_docterm, doc_labels_training, 5, 1)\n",
    "\n",
    "print(\"Predicted class: {} \\n k-nearest neighbors:\\n{}\".format(predicted_class, k_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1b): Create a function to compute the classification accuracy over the test data set (ratio of correct predictions to the number of test instances). \n",
    "This function will call the classifier function on all the test instances and in each case compares the actual test class label to the predicted class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#So we need the test instances and their labels\n",
    "\n",
    "#Training data matrix\n",
    "test_data = pd.read_table(\"newsgroups/testMatrixModified.txt\", header=None)\n",
    "#Turn into a doc-term matrix\n",
    "test_data_docterm = np.array(test_data.T)\n",
    "\n",
    "\n",
    "#Training labels\n",
    "test_labels = pd.read_table(\"newsgroups/testClasses.txt\", header=None)\n",
    "test_labels.drop(0, axis=1, inplace=True)\n",
    "#Turn into a list of classes\n",
    "doc_labels_test = list(test_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function**  \n",
    "- Careful to understand how knn function works, and what happens when it's nested within this new testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we'll run rows of the testing data in the knn function\n",
    "\n",
    "def knn_tester(numTestVecs, testData, trainData, labels, k, measure):\n",
    "    errorCount = 0.0\n",
    "    for i in range(numTestVecs):\n",
    "        #Use the first i rows of the testing data, one-by-one, in the knn function\n",
    "        predicted_class, neighbors = knn_function(testData[i,:], trainData, doc_labels_training, k, measure)\n",
    "        #If the two classes don't match, add 1 to the error count\n",
    "        if (predicted_class != labels[i]): errorCount += 1.0\n",
    "    #Give the accuracy\n",
    "    if measure == 0:\n",
    "        print(\"\\nClassified {} documents. \\nThe total ACCURACY using Euclidean distance is: {}%\".format(numTestVecs, 100*(1 - (errorCount/float(numTestVecs)))))\n",
    "    elif measure == 1:\n",
    "        print(\"\\nClassified {} documents. \\nThe total ACCURACY using Cosine similarity is: {}%\".format(numTestVecs, 100*(1 - (errorCount/float(numTestVecs)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 10 documents. \n",
      "The total ACCURACY using Cosine similarity is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "knn_tester(numTestVecs=10, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 10, measure = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c) Use the testing function on various amounts of test data rows, using both Euclidean and Cosine measures of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 10 documents. \n",
      "The total ACCURACY using Euclidean distance is: 90.0%\n",
      "\n",
      "Classified 10 documents. \n",
      "The total ACCURACY using Cosine similarity is: 100.0%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Euclidean vs Cosine\n",
    "# 10 testing docs\n",
    "# 5 nearest neighbors\n",
    "print(knn_tester(numTestVecs=10, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 5, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=10, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 5, measure = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 10 documents. \n",
      "The total ACCURACY using Euclidean distance is: 80.0%\n",
      "\n",
      "Classified 10 documents. \n",
      "The total ACCURACY using Cosine similarity is: 100.0%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 10 testing docs\n",
    "# 10 nearest neighbors\n",
    "print(knn_tester(numTestVecs=10, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 10, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=10, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 10, measure = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Euclidean distance is: 83.33333333333334%\n",
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Cosine similarity is: 96.66666666666667%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 30 testing docs\n",
    "# 5 nearest neighbors\n",
    "print(knn_tester(numTestVecs=30, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 5, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=30, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 5, measure = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Euclidean distance is: 76.66666666666666%\n",
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Cosine similarity is: 93.33333333333333%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 30 testing docs\n",
    "# 10 nearest neighbors\n",
    "print(knn_tester(numTestVecs=30, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 10, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=30, testData = test_data_docterm, trainData = train_data_docterm, labels = doc_labels_test, k = 10, measure = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "It seems that cosine similarity outperforms Euclidean distance in this application. It is more accurate, and suffers less problems when given a larger number of neighbors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d) Modify the training and test datasets so term weights are converted to TFxIDF weights (instead of raw term frequencies). Then rerun the evaluation on the range of K values (same as above) and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we get our datasets into term frequency x inverse document frequency format?  \n",
    "  \n",
    "Formula: *w = tf x log(N / n)*  \n",
    "- T = a term in document D  \n",
    "- tf = frequency of that term T in document D  \n",
    "- idf = inverse document frequency of term T in C  \n",
    "- N = total number of docs in the collection C  \n",
    "- n = the number of docs in C that contain term T  \n",
    "- idf = log(N/n)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We already computed term frequency:\n",
    "train_data = pd.read_table(\"newsgroups/trainMatrixModified.txt\", header=None)\n",
    "\n",
    "#For the testing data\n",
    "test_data = pd.read_table(\"newsgroups/testMatrixModified.txt\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function**: converts a term-document matrix into a tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A function for converting a term-document matrix into tf-idf format\n",
    "def tf_idf_converter(term_doc_mat):\n",
    "    #rotate the matrix so rows are doc's and col's are terms\n",
    "    tf_mat = np.array(term_doc_mat.T)\n",
    "    #N = number of docs (length of new doc-term matrix)\n",
    "    N = tf_mat.shape[0]\n",
    "    #Define n for each column (term) and get tf x idf for each column\n",
    "    for col in range(tf_mat.shape[1] - 1):\n",
    "        n = tf_mat[:, col].astype(bool).sum()\n",
    "        tf_mat[:, col] = tf_mat[:, col] * np.log(N/n)\n",
    "    return tf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create tf-idf matrices for the training and testing sets\n",
    "train_tfidf = tf_idf_converter(train_data)\n",
    "test_tfidf = tf_idf_converter(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.54517744448 2.0\n"
     ]
    }
   ],
   "source": [
    "#Did it work?\n",
    "print(train_tfidf[0,0], np.array(train_data.T)[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_for_function = train_tfidf[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 \n",
      " k-nearest neighbors:\n",
      "[[ 5.54517744  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 5.54517744  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Use these as inputs for the knn function\n",
    "predicted_class, k_neighbors = knn_function(vec_for_function, \n",
    "                                            train_tfidf, doc_labels_training, \n",
    "                                            5, 1)\n",
    "\n",
    "print(\"Predicted class: {} \\n k-nearest neighbors:\\n{}\".format(predicted_class, k_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the KNN function using the tf-idf matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Euclidean distance is: 50.0%\n",
      "\n",
      "Classified 30 documents. \n",
      "The total ACCURACY using Cosine similarity is: 50.0%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#Test the knn function when using tf idf matrices\n",
    "print(knn_tester(numTestVecs=30, testData = test_tfidf, trainData = train_tfidf, labels = doc_labels_test, k = 5, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=30, testData = test_tfidf, trainData = train_tfidf, labels = doc_labels_test, k = 5, measure = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 50 documents. \n",
      "The total ACCURACY using Euclidean distance is: 48.0%\n",
      "\n",
      "Classified 50 documents. \n",
      "The total ACCURACY using Cosine similarity is: 48.0%\n",
      "None \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print(knn_tester(numTestVecs=50, testData = test_tfidf, trainData = train_tfidf, labels = doc_labels_test, k = 5, measure = 0), \"\\n\",\n",
    "      knn_tester(numTestVecs=50, testData = test_tfidf, trainData = train_tfidf, labels = doc_labels_test, k = 5, measure = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**  \n",
    "Seems that simply subbing in the tf-idf matrices into the same KNN function reduces accuracy.  \n",
    "Oddly, the performance of the two distance measures is now identical **(error??)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
